{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "580835ea-f0b2-4af4-8fb8-a2fcade8630b",
   "metadata": {},
   "source": [
    "## PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6540660-383b-43fa-9446-b4dbdc1c20f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import PIL\n",
    "import cv2\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43e58fd0-7191-473d-bd93-ceaeaebd0d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing algorithm\n",
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc54bb8a-6af1-4a00-9b3a-68186eb26320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below value to be changed only \n",
    "input_shape = (224, 224, 3)\n",
    "algorithm = VGG16(include_top=False, input_shape=input_shape)\n",
    "saving_model_name = 'vgg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6030176-46dc-4d5a-ab8c-7fd60348da9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping of class indices to labels\n",
    "int_to_label = {v: k for k, v in {'buildings': 0, 'forest': 1, 'glacier': 2, 'mountain': 3, 'sea': 4, 'street': 5}.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b34bb3e-cd02-4475-941e-7b71e306365c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths and file names\n",
    "folder_path = \"C:/Users/ys726/Desktop/DL/datasets/intel\"\n",
    "file_x = 'X_test.npy'\n",
    "file_y = 'y_test.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5675f27f-242b-401a-9547-8667ededea34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function for loading and preprocessing data\n",
    "def load_and_preprocess_data():\n",
    "    path_x = os.path.join(folder_path, file_x)\n",
    "    path_y = os.path.join(folder_path, file_y)\n",
    "\n",
    "    if os.path.exists(path_x) and os.path.exists(path_y):\n",
    "        X = np.load(path_x)\n",
    "        y = np.load(path_y)\n",
    "        print(\"Files loaded successfully.\")\n",
    "    else:\n",
    "        train_dir = pathlib.Path(\"C:/Users/ys726/Desktop/DL/datasets/intel/seg_test\")\n",
    "\n",
    "        intel_image_dict = {\n",
    "            'buildings': list(train_dir.glob('buildings/*')),\n",
    "            'forest': list(train_dir.glob('forest/*')),\n",
    "            'glacier': list(train_dir.glob('glacier/*')),\n",
    "            'mountain': list(train_dir.glob('mountain/*')),\n",
    "            'sea': list(train_dir.glob('sea/*')),\n",
    "            'street': list(train_dir.glob('street/*')),\n",
    "        }\n",
    "\n",
    "        intel_labels_dict = {\n",
    "            'buildings': 0,\n",
    "            'forest': 1,\n",
    "            'glacier': 2,\n",
    "            'mountain': 3,\n",
    "            'sea': 4,\n",
    "            'street': 5\n",
    "        }\n",
    "\n",
    "        X, y = [], []\n",
    "        for name, images in intel_image_dict.items():\n",
    "            for image in images:\n",
    "                img = cv2.imread(str(image))\n",
    "                resized_image = cv2.resize(img, (224, 224))\n",
    "                X.append(resized_image)\n",
    "                y.append(intel_labels_dict[name])\n",
    "\n",
    "        X = np.array(X) / 255.0\n",
    "        y = np.array(y)\n",
    "\n",
    "        np.save(path_x, X)\n",
    "        np.save(path_y, y)\n",
    "        print(\"Data processed and saved.\")\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6bf7ad-5fce-4605-8bf1-2939baceeeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function for creating the model\n",
    "def create_model(input_shape=input_shape):\n",
    "    model = algorithm\n",
    "    model.trainable = False\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        model,\n",
    "        layers.Flatten(),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        layers.Dense(6, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443cfc8b-b7d6-4584-a11f-c97dfe6478f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138c3038-56ae-4baa-b218-97f731bc9ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function for training the model\n",
    "def train_model(X_train, y_train, epochs_gpu=1, epochs_cpu=1):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        with tf.device('/GPU:0'):\n",
    "            model = create_model(input_shape)\n",
    "            model.fit(X_train, y_train, epochs=epochs_gpu)\n",
    "            end_time = time.time()\n",
    "            print(\"GPU Execution time:\", end_time - start_time)\n",
    "            return model\n",
    "    except tf.errors.InvalidArgumentError:\n",
    "        print(\"GPU not available. Training on CPU...\")\n",
    "\n",
    "    with tf.device('/CPU:0'):\n",
    "        model = create_model(input_shape)\n",
    "        model.fit(X_train, y_train, epochs=epochs_cpu)\n",
    "        end_time = time.time()\n",
    "        print(\"CPU Execution time:\", end_time - start_time)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fb36e9-6c50-4fe5-99cf-6744d8a7d6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function for evaluating the model\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f\"Test Loss: {loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6165c671-915e-48f8-a7cf-61dcaacc92e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(X, label, title):\n",
    "    plt.imshow(X)\n",
    "    plt.xlabel(int_to_label[label])\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ef90d2-52f6-471d-80bf-10eff85d2d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction function with image display\n",
    "def predict_image(model, image_path, actual_label=None):\n",
    "    # Preprocess the image\n",
    "    origonal_image = PIL.Image.open(image_path)\n",
    "    img = cv2.imread(image_path)\n",
    "    img_resized = cv2.resize(img, (224, 224))\n",
    "    img_normalized = img_resized / 255.0\n",
    "    img_expanded = np.expand_dims(img_normalized, axis=0)  # Add batch dimension\n",
    "\n",
    "    # Make a prediction\n",
    "    predictions = model.predict(img_expanded)\n",
    "    predicted_class = np.argmax(predictions, axis=1)[0]\n",
    "\n",
    "    # Get the readable label\n",
    "    actual_label = image_path.split('/')[-2]\n",
    "    predicted_label = int_to_label[predicted_class]\n",
    "\n",
    "    # Plot the original image\n",
    "    plt.figure(figsize=(10, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(origonal_image)\n",
    "    plt.title('Original Image')\n",
    "    plt.xlabel(actual_label)\n",
    "\n",
    "    # Plot the predicted image\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plot_sample(img_resized, predicted_class, 'Predicted Image')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()    \n",
    "\n",
    "    return predicted_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48308f0b-ff20-4c49-9ba5-81bf39369ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main pipeline function\n",
    "def main_pipeline():\n",
    "    X, y = load_and_preprocess_data()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "    model = train_model(X_train, y_train)\n",
    "    evaluate_model(model, X_test[:50], y_test[:50])\n",
    "\n",
    "    # Saving the model\n",
    "    model.save(f'{saving_model_name}.h5')\n",
    "    print(f\"Model saved as {saving_model_name}.h5\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e142b1c-2b04-4acf-9c95-b945f0cd551e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = main_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bbb701-1c65-4769-a3a6-892b1099dabf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example usage of prediction function\n",
    "paths = [\n",
    "    \"C:/Users/ys726/Desktop/DL/datasets/intel/seg_train/buildings/1877.jpg\",\n",
    "    \"C:/Users/ys726/Desktop/DL/datasets/intel/seg_train/forest/430.jpg\", \n",
    "    \"C:/Users/ys726/Desktop/DL/datasets/intel/seg_train/glacier/417.jpg\",\n",
    "    \"C:/Users/ys726/Desktop/DL/datasets/intel/seg_train/mountain/6932.jpg\",\n",
    "    \"C:/Users/ys726/Desktop/DL/datasets/intel/seg_train/sea/11667.jpg\",\n",
    "    \"C:/Users/ys726/Desktop/DL/datasets/intel/seg_train/street/8690.jpg\"\n",
    "]\n",
    "\n",
    "# Process and plot images\n",
    "for path in paths:\n",
    "    predict_image(final_model, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bd930a-7b3e-49f4-b15e-71b3fb6b8fcb",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629ab7fe-2221-47d7-bc57-51f9df2908e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model_path = 'dummy.h5'\n",
    "model_load = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0360f7-6092-42c0-8ac2-dd7f946b1b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run Below Function before predicting\n",
    "#Predict Image\n",
    "#int_to_label\n",
    "#plot_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3280664d-d5a8-4329-8e71-b8212f3448fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"C:/Users/ys726/Desktop/DL/datasets/intel/seg_train/sea/224.jpg\"\n",
    "predict_image(model_load, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9589ba-003e-4433-b644-79ead3e2421d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e6de87-dc66-4525-86c7-52c05b5bf3b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0e023f-8dfb-4062-9f4e-c000f1606815",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da077b83-7316-4282-bd49-62943bb0e348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89db6d5f-3dc6-4cb3-94a2-777824be2403",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
